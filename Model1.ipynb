{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional\n",
    "# from keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f985c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(Path('AllCSVs/X_scaled.npy'))\n",
    "y = np.load(Path('AllCSVs/y_scaled.npy'))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e823fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reshape input to be [samples, time steps, features]\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec221e",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e7c45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "n_outputs = X_train.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, input_shape=(None, 4))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(n_outputs)) \n",
    "model.add(Dense(n_outputs))\n",
    "\n",
    "# model = keras.models.load_model('modelV2.h5')\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "\n",
    "mc = ModelCheckpoint('best_model1.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=1, \n",
    "          batch_size=10000, \n",
    "          verbose=1, \n",
    "          validation_split=0.2,\n",
    "          callbacks=[mc])\n",
    "\n",
    "# model.save('model1_Transformer.h5')\n",
    "#loss: 847995.6250 - val_loss: 333785.3438\n",
    "y_pred = model.predict(X_test, batch_size=90000)\n",
    "mse_1 = ((y_pred - y_test)**2).mean(axis=0)\n",
    "mse = np.square(np.subtract(y_test,y_pred)).mean() \n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE')\n",
    "print('[', math.sqrt(mse_1[0]),math.sqrt(mse_1[1]), math.sqrt(mse_1[2]), math.sqrt(mse_1[3]), ']')\n",
    "print('Y_test Min:', np.amin(y_test, axis=0),'Y_test Max:', np.amax(y_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472175cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1Final.h5')\n",
    "y_pred = model.predict(X_test, batch_size=90000)\n",
    "mse_1 = ((y_pred - y_test)**2).mean(axis=0)\n",
    "mse = np.square(np.subtract(y_test,y_pred)).mean() \n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE')\n",
    "print('[', math.sqrt(mse_1[0]),math.sqrt(mse_1[1]), math.sqrt(mse_1[2]), math.sqrt(mse_1[3]), ']')\n",
    "print('Y_test Min:', np.amin(y_test, axis=0),'Y_test Max:', np.amax(y_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5eac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,1231,13123,345634,96341,54232,26743,76345,90000]:\n",
    "    print('Pred Pos: [{:f},{:f}] Spd: [{:f},{:f}]'.format(y_pred[i][0],y_pred[i][1],y_pred[i][2],y_pred[i][3]))\n",
    "    print('Test Pos: [{:f},{:f}] Spd: [{:f},{:f}]'.format(y_test[i][0],y_test[i][1],y_test[i][2],y_test[i][3]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c8715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca50bc1f",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610e520",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.layers import TransformerBlock\n",
    "\n",
    "# Prepare the data\n",
    "input_shape = (10,4)  # input shape of each time series sequence\n",
    "num_classes = X_train.shape[2]\n",
    "\n",
    "# Define the model\n",
    "inputs = Input(shape=input_shape)\n",
    "x = inputs\n",
    "embedding_dim = 4 \n",
    "num_heads = 8\n",
    "ff_dim = 4 \n",
    "\n",
    "# Time series embedding layer\n",
    "x = TransformerBlock(embed_dim=embedding_dim, num_heads=num_heads, ff_dim=ff_dim)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(num_classes)(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "n_feats = 4\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "\n",
    "mc = ModelCheckpoint('model1_Transformer.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# for i in range(0,100):\n",
    "# print('Epoch:', i)\n",
    "# X_train, y_train = get_data(X_attacker_train, X_normal_train)\n",
    "# y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=1, \n",
    "          batch_size=9000, \n",
    "          validation_split=0.1,\n",
    "#           callbacks=[mc]\n",
    "         )\n",
    "model.summary()\n",
    "# model.save('model1_Transformer.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          epochs=100, \n",
    "          batch_size=2000, \n",
    "#           validation_split=0.1,\n",
    "#           callbacks=[mc]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d9592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[0:1])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab59824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size=90000)\n",
    "mse_1 = ((y_pred - y_test)**2).mean(axis=0)\n",
    "mse = np.square(np.subtract(y_test,y_pred)).mean() \n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE')\n",
    "print('[', math.sqrt(mse_1[0]),math.sqrt(mse_1[1]), math.sqrt(mse_1[2]), math.sqrt(mse_1[3]), ']')\n",
    "print('Y_test Min:', np.amin(y_test, axis=0),'Y_test Max:', np.amax(y_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6afcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,1231,13123,345634,96341,54232,26743,76345,90000]:\n",
    "    print('Pred Pos: [{:f},{:f}] Spd: [{:f},{:f}]'.format(y_pred[i][0],y_pred[i][1],y_pred[i][2],y_pred[i][3]))\n",
    "    print('Test Pos: [{:f},{:f}] Spd: [{:f},{:f}]'.format(y_test[i][0],y_test[i][1],y_test[i][2],y_test[i][3]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d370c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# from tensorflow.keras.layers import TransformerBlock\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "#     def get_config(self):\n",
    "\n",
    "#         config = super().get_config().copy()\n",
    "#         config.update({\n",
    "#             'num_heads': self.num_heads,\n",
    "#             'embed_dim': self.embed_dim,\n",
    "#             'ff_dim': self.ff_dim,\n",
    "#         })\n",
    "#         return config\n",
    "#https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e04d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "303755d0",
   "metadata": {},
   "source": [
    "# MAKING CSVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41283387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional\n",
    "# from keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "model = keras.models.load_model('model1Final.h5')\n",
    "# y_pred = model.predict(X_test, batch_size=90000)\n",
    "# mse_1 = ((y_pred - y_test)**2).mean(axis=0)\n",
    "# mse = np.square(np.subtract(y_test,y_pred)).mean() \n",
    "# rmse = math.sqrt(mse)\n",
    "# print('RMSE')\n",
    "# print('[', math.sqrt(mse_1[0]),math.sqrt(mse_1[1]), math.sqrt(mse_1[2]), math.sqrt(mse_1[3]), ']')\n",
    "# print('Y_test Min:', np.amin(y_test, axis=0),'Y_test Max:', np.amax(y_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7eb251",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_folder = 'AllCSVs'\n",
    "csvs = sorted(glob.glob('{}/*.csv'.format(start_folder)))\n",
    "df_list_og = []\n",
    "\n",
    "for c in csvs:\n",
    "    df = pd.read_csv(c)\n",
    "    for i in np.unique(df.sender):\n",
    "        df_list_og.append(df[df.sender.isin([i])].copy())\n",
    "    #     df[df.ID.isin([subs[0]])&df.Vigil.isin(vigils[0])].copy()\n",
    "    \n",
    "print(len(df_list_og))\n",
    "# df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa770b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_list_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a695e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_list = df_list_og.copy()\n",
    "# df_attacker = []\n",
    "# df_normal = []\n",
    "window_size = 10\n",
    "overlap_size = 9\n",
    "\n",
    "# for count, j in enumerate(df_list):\n",
    "for count in range(20712, len(df_list)):#46012\n",
    "    j = df_list[count]\n",
    "    if j.attackerType.any() == 0:\n",
    "        j = j.iloc[:,[4,5,6,7]]\n",
    "        for start_idx in range(0, len(j)-window_size, window_size - overlap_size):\n",
    "            end_idx = start_idx + window_size\n",
    "            df_chunk = j.iloc[start_idx:end_idx]\n",
    "            y_test = np.expand_dims(np.asarray(df_chunk), axis=0)\n",
    "\n",
    "            pred_idx = j.iloc[end_idx].name\n",
    "            y_pred = model.predict(y_test, verbose=0)\n",
    "            \n",
    "            df_list[count].loc[pred_idx, 'pos0_Pred'] = y_pred[0][0]\n",
    "            df_list[count].loc[pred_idx, 'pos1_Pred'] = y_pred[0][1]\n",
    "            df_list[count].loc[pred_idx, 'spd0_Pred'] = y_pred[0][2]\n",
    "            df_list[count].loc[pred_idx, 'spd1_Pred'] = y_pred[0][3]\n",
    "#             display(df_chunk)\n",
    "           # df_normal.append(df_chunk)\n",
    "        df_list[count] = df_list[count].drop(df_list[count].index[-1])\n",
    "        df_list[count].to_csv('CSVsPred/Pred_Car_{}_normal.csv'.format(count)) \n",
    "        print('CSVsPred/Pred_Car_{}_normal.csv'.format(count))\n",
    "    elif j.attackerType.any() == 1:\n",
    "#         print('Attack')\n",
    "        j = j.iloc[:,[4,5,6,7]]\n",
    "#         for start_idx in range(0, len(j)-window_size, window_size - overlap_size):\n",
    "#             end_idx = start_idx + window_size\n",
    "#             df_chunk = j.iloc[start_idx:end_idx]\n",
    "#             y_test = np.expand_dims(np.asarray(df_chunk), axis=0)\n",
    "\n",
    "#             pred_idx = j.iloc[end_idx].name\n",
    "#             y_pred = model.predict(y_test, verbose=0)\n",
    "            \n",
    "#             df_list[count].loc[pred_idx, 'pos0_Pred'] = y_pred[0][0]\n",
    "#             df_list[count].loc[pred_idx, 'pos1_Pred'] = y_pred[0][1]\n",
    "#             df_list[count].loc[pred_idx, 'spd0_Pred'] = y_pred[0][2]\n",
    "#             df_list[count].loc[pred_idx, 'spd1_Pred'] = y_pred[0][3]\n",
    "# #             display(df_chunk)\n",
    "# #             df_attacker.append(df_chunk)\n",
    "#         df_list[count] = df_list[count].drop(df_list[count].index[-1])\n",
    "#         print('CSVsPred/Pred_Car_{}_attacker.csv'.format(count))\n",
    "#         df_list[count].to_csv('CSVsPred/Pred_Car_{}_attacker.csv'.format(count)) \n",
    "\n",
    "# df_normal = np.asarray(df_normal)\n",
    "# df_attacker = np.asarray(df_attacker)\n",
    "\n",
    "# df_normal[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
